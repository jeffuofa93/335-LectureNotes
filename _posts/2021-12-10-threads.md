---
layout: post
title:  "Threads"
date:   2021-12-10 14:51:20 -0700
categories: jekyll update
---

<link rel="stylesheet" href="/assets/style.css">

## Processes

- For a long time each computer had 1 CPU that could run 1 instruction at a time
- Now we have computers with many cores and threads but still computers run way more processes then their are processors
- Example: Misurda had 4 cores and 8 threads and 223 processes
![img.png](/assets/threads/img.png?style=centerme)

## Juggling Analogy

- The idea behind juggling is that we have all this time between when the ball is in our hand in when it's in the air
- Processors can do 1 billion operations a second so the processor has the majority of it's time waiting for
  instructions from a program
- Processors do juggling by switching between aplications to be able to run many many processes at a time by juggling
  between the processes
- This is called scheduling
- We shouldn't make any assumptions about scheduling

## Processes - Psuedo parrallelsim vs Real Parellelism

- Psuedo parallelsim - like juggling, for our programs when we have down time or we are waiting for some input instead
  of stopping other execution we can do other work. If fast enough this appears identical to actually doing 2 things at
  the same time
- Real Parallelism - actual performing 2 operations at the exact same time
![img_1.png](/assets/threads/img_1.png?style=centerme)

## What Are Threads

- seperate processes like zoom and firefox are restricted from acessing the state of each other by the OS
- Threads allow us to spawn to sub-processes inside the the same program that have acess to each others state
- Example word program
  - a thread for the regular writing of user input to the screen
  - another thread to do background tasks like auto-saving
![img_3.png](/assets/threads/img_3.png?style=centerme)

## Programming Perspective

- Every process has at least a single thread
- If a process has only one thread it is single-threaded
- A process can have multiple threads which make it multi-threaded
![img_4.png](/assets/threads/img_4.png?style=centerme)

## Single-Threaded vs Multi-Threaded

- **Concurrency**
  - concurrency can either be pseudo or real parrelism
  - more then one thread at a time
- **Multi-threaded**
  - when more than one thread is running at the same time
- example with sleep in loop, can we do other work while the program is sleeping?
- The main thread is implicit
![img_5.png](/assets/threads/img_5.png?style=centerme)

## Using the Thread Class

- Can create a new class that extends Thread with a run method that is the main of this new thread
- Then in main we can create a new instance of the thread class we created
- After we start the second thread we have two threads active mains thread and the newThread
- Once we start a second thread we have no gurantees about the order or timining of when the operations will be
  performed in either threads
![img_6.png](/assets/threads/img_6.png?style=centerme)

## The Runnable Interface

- Another way of creating a thread is implementing the Runnable interface
- This is a functional interface where we have to implement a run method
- Runnable and Thread is to allow us to inherit from another class besides thread
![img_7.png](/assets/threads/img_7.png?style=centerme)

## Single Threaded vs Multi-Threaded

- Code example
- Main thread creates 2 additional threads
- With the sleep in each thread the program juggles over to the next thread
![img_8.png](/assets/threads/img_8.png?style=centerme)

## Concurrent Programming

- Biggest problem with concurrent programming is avoiding conflicts between threads
- What happens when one thread tries to access something while another is modifying the same data?
![img_9.png](/assets/threads/img_9.png?style=centerme)

## Thread Safety

- If code is not thread safe then two threads accessing the same data can corrupt teh data
![img_10.png](/assets/threads/img_10.png?style=centerme)

## Race Condition

- Example: adding and element to a queue on two different threads
- We could either at the element to the queue in thread0 first or we could add the element to the queue in thread1 first
- The issue arises when we either overwrite data by writing to the same index or we skip an index in the queue and now
  have junk data in the queue
- Things we need to be true for a race condition
- Thread switching isn't resctricted to just lines in code but can happen between any two machine instructions
  - Shared global data
  - accessed from 2+ threads
  - read state and act upon it in non atomic fashion
![img_11.png](/assets/threads/img_11.png?style=centerme)
![img_13.png](/assets/threads/img_13.png?style=centerme)
- Example with 3 threads
  - Just the existent of multiple threads does not make threads unsafe
- Two cause a Race Condition we need
  - Shared global state
  - Code accessing data in a non atomic way
  - Interuptted for conflicting code, something acesses the same shared state
- A single machine instruction is atomic
- \*\*- Non atomic

  - a) read
  - b) act up on it

- Race condition - Between a and b the value changes out from under us so that our action is now wrong\*\*

![img_15.png](/assets/threads/img_15.png?style=centerme)

## Summary of What Cause a Race Condition

- We have a program with at least 2 threads
- We have shared global state between two threads
- We have code accessing state in non-atomic ways
  - atomic code is a single machine instruction
  - non atomic exmaple is reading data then acting upon it
- We are interrupted on access for conflicting code
  - this occurs between the read and acting upon non-atomic code
  - The value is changed from the read out from under us so that our action is now incorrect
- Race conditions can be latent -> invisible
  - Given the queue example we could run the code 100 times and never have the error occur
  - We can have possible race conditions in our code just waiting to become bugs

## Race Condition 1

![img_16.png](/assets/threads/img_16.png?style=centerme)

## Race Condition 2

- This is where we don't increment the counter
- This happens because tail++ is actually 3 instructions in machine code
  - We have the lw, add then the sw
  - What can happen is thread1 get interuppted after it's lw but before it's store word
  - In this case then both thread1 and thread2 read say 3 from memory increment it and write it back
  - tail++ when tail = 3 now = 4
![img_17.png](/assets/threads/img_17.png?style=centerme)

## Example of count skip Race Condition

![img_18.png](/assets/threads/img_18.png?style=centerme)

## What We Want to Happen

- Critical Region

  - Block of code with potential race conde

- One thread wins the race to enter the critical region first
- Then when the thread switches if thread1 tries to enter the critical region it is blocked
- The interruption isn't the problem the blocking only occurs if a different thread tries to access the same
  critical region
![img_20.png](/assets/threads/img_20.png?style=centerme)

![img_19.png](/assets/threads/img_19.png?style=centerme)

## Atomic Actions

- making something atomic makes access to any critical regions mutually exclusive
- Bathroom Analogy
  - The bathroom is mutually exclusive only 1 person can be in at a time
  - When someone occupies the restroom they lock the door preventing access to the bathroom for other people
  - Other people can still walk around the store but they cannot enter the bathroom
  - If another person has to use the bathroom they try to open, see that it is locked and then they wait for it to
    be unlocked
![img_21.png](/assets/threads/img_21.png?style=centerme)

## Using synchronized

- every class has a hidden static lock
- we can add this static lock called **synchronized** as a decorator to lock access to a class object.
  - This means that while the method with synchronized is running any other threads with the object are unable to
    access statically synchronized methods on the class
![img_22.png](/assets/threads/img_22.png?style=centerme)

- Synchronized is a class based lock so it locks all static synchronized methods of the same class
![img_23.png](/assets/threads/img_23.png?style=centerme)
![img_24.png](/assets/threads/img_24.png?style=centerme)

- Non static synchronized
- When synchronized is not static instead of locking the entire class it locks the instance of the class instead
- All synchronized methods are still guarded by the same lock the only difference is that instead of locking the
  entire class with static synchronized we just lock all synchronized methods in the instance of that class
![img_25.png](/assets/threads/img_25.png?style=centerme)

## Using volatile

![img_26.png](/assets/threads/img_26.png?style=centerme)

## Without volatile

![img_27.png](/assets/threads/img_27.png?style=centerme)

## With volatile

![img_28.png](/assets/threads/img_28.png?style=centerme)

- Volatile ensures that every time we access a field it is read from memory instead of being accessed from a register
- volatile means between reads of x the value could change
  - parrellel code cause this
  - hardware button
- This is important because we could have written the data to memory in another thread and now my register value is
  out of sync with the actual value in memory

## Non Volatile diagram

- the value from the register not memory is stale in thread1
- This does not mean we have a race condition it just means that changing the value but before reading it again
  another thread came an changed the value
![img_29.png](/assets/threads/img_29.png?style=centerme)

## Volatile Diagram

![img_30.png](/assets/threads/img_30.png?style=centerme)

## Locks and JVM

- When we call the method we aquire the lock
- When we return we remove the lock
- This is all handled by the JVM

## Volatile and Synchronized Graph

- Volatile is a message to the compiler
  - Every time you read this value it needs to be read from memory again instead of using any value stored in a register
![img_31.png](/assets/threads/img_31.png?style=centerme)

## Using synchronized Blocks

- We can make synchronized even granular by creating a synchronized call inside a method that passes in the object
  we want to synchronize
- This allows us to lock even smaller sections of code that will only lock the object in the field of the instance
  instead of the entire instance
![img_32.png](/assets/threads/img_32.png?style=centerme)

## Using conncurent.atmoic

- If you declare an AtomicInteger is implements all the synchronized code in the background
![img_33.png](/assets/threads/img_33.png?style=centerme)

## The java.util.concurrent.atomic Package

- Making an integer atomic doesn't fully solve our Race conditions
- It only prevents the value of the atomicInteger from being changed at the same time but getting an integer value
  and setting the value in the queue are two different operations so we could still increment the index and then
  switch to the other thread and still cause a race condition
![img_34.png](/assets/threads/img_34.png?style=centerme)

## Concurrent and Synchronized Collections

![img_35.png](/assets/threads/img_35.png?style=centerme)

## Stopping a Thread

- issue is that if we have synchronized code that uses state that needs to be changed by a different thread then the
  other thread can never access that state because it is locked by the sychronized block
- This is called **lock starvation**
- Bathroom analogy someone goes into the bathroom and never leaves, no one else can ever go to the bathroom
![img_36.png](/assets/threads/img_36.png?style=centerme)

## Stopping a Thread Fix

- we can instead only synchronize the reading of the value inside the loop and exit with a break
![img_37.png](/assets/threads/img_37.png?style=centerme)

## Waiting for a Thread to Finish

- thread.join() method allows us to block the thread we were called from while our thread completes some work
![img_38.png](/assets/threads/img_38.png?style=centerme)
- If you have 2 threads running off main the JVM under the hood has a join it calls on main if it tries to return
  while there are threads running, so that the JVM doesn't kill the program until all threads stop
![img_39.png](/assets/threads/img_39.png?style=centerme)
![img_40.png](/assets/threads/img_40.png?style=centerme)

## Passing Data Between Threads

- Producer Consumer patter
  - consumer uses information from the producer
  - producers make the information
- This is only useful when the producer and consumer operate at different speeds
- We use a Java Blocking queue to communicate between producer and consumer
![img_41.png](/assets/threads/img_41.png?style=centerme)

## BlockingQueue

- thread safe
- fixed size
- Idea with the blockingqueue is the put and take method will block and wait if the queue is full or empty which
  allows for the producer or consumer to catch up to either fill the queue or remove elements before we operate on it
![img_42.png](/assets/threads/img_42.png?style=centerme)

## Concurrent Programming Caveats

- Very hard to debug
- If you use too many locks then you lose the speed improvements from multi-threading
![img_43.png](/assets/threads/img_43.png?style=centerme)
